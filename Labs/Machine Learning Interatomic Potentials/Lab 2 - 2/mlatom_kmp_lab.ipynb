{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#  Hands-On Lab: Teaching a Computer to Predict Molecular Energies\n",
        "\n",
        "**Based on:** Yi-Fan Hou and Pavlo O. Dral. *Kernel method potentials.* In Quantum Chemistry in the Age of Machine Learning, Elsevier (2023).  \n",
        "**DOI:** [10.1016/B978-0-323-90049-2.00020-2](https://doi.org/10.1016/B978-0-323-90049-2.00020-2)\n",
        "\n",
        "---\n",
        "\n",
        "##  What This Lab Is About\n",
        "\n",
        "Imagine you're a chemist studying how two hydrogen atoms interact. To know the energy at *every possible distance*, you'd normally need to run thousands of expensive quantum chemistry calculations. \n",
        "\n",
        "**The big idea of this lab:** What if you only run a *small number* of those calculations, then train a machine learning model to predict the rest â€” almost instantly?\n",
        "\n",
        "That's exactly what we'll do.\n",
        "\n",
        "```\n",
        "  H â†â€”â€”â€”â€”â€”â€”â†’ H\n",
        "     distance R\n",
        "  \n",
        "  At each R, there's an energy E(R).\n",
        "  The curve of E vs R is the Potential Energy Surface (PES).\n",
        "  Our job: learn this curve from data!\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## Your Journey Through This Lab\n",
        "\n",
        "| Part | What You'll Do | Points |\n",
        "|------|---------------|--------|\n",
        "| **Part 1** | Set up tools and load data | â€” |\n",
        "| **Part 2** | Train a KREG machine learning model | â€” |\n",
        "| **Part 3** | Optimize the Hâ‚‚ geometry using your model | - |\n",
        "| **Part 4** | Analyse and validate accuracy | -|\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Key Concepts \n",
        "\n",
        "**What is a Kernel Ridge Regression (KREG) model?**  \n",
        "Think of it like a \"smart interpolation\". When you ask the model for the energy at a new H-H distance, it looks at all the training examples and says: *\"this new distance is most similar to these training points, so my prediction should be a weighted combination of their energies.\"*  \n",
        "The word **kernel** refers to the similarity function â€” we use a Gaussian (bell-curve) to say how similar two distances are.\n",
        "\n",
        "**What is a Potential Energy Surface (PES)?**  \n",
        "A graph of molecular energy vs. geometry. For Hâ‚‚, it's just energy vs. H-H distance. The lowest point on this curve tells us the stable \"equilibrium\" bond length.\n",
        "\n",
        "**What is geometry optimization?**  \n",
        "Starting from a random H-H distance, we \"roll downhill\" on the energy surface until we find the minimum â€” the most stable geometry.\n",
        "\n",
        "---\n",
        "\n",
        "##  New to Python? Quick Reference\n",
        "\n",
        "```python\n",
        "# A function is like a recipe:\n",
        "def my_function(ingredient1, ingredient2):\n",
        "    result = ingredient1 + ingredient2   # do something\n",
        "    return result                        # give back the result\n",
        "\n",
        "# A loop repeats for each item:\n",
        "for item in [1, 2, 3]:\n",
        "    print(item)          # prints 1, then 2, then 3\n",
        "\n",
        "# numpy arrays are like spreadsheet columns:\n",
        "import numpy as np\n",
        "my_array = np.array([1.0, 2.0, 3.0])\n",
        "print(my_array * 2)      # [2.0, 4.0, 6.0]\n",
        "```\n",
        "\n",
        "> **Tip:** Run each cell with **Shift + Enter**. If you get an error, read it carefully â€” it usually tells you exactly what went wrong!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 1: Setup â€” Getting Your Tools Ready \n",
        "\n",
        "Just like a chemist needs a clean lab bench before starting an experiment, we need to install and import our tools.\n",
        "\n",
        "> **Nothing to fill in here â€” just run each cell!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ed303007629c1634c936026485d1357c",
          "grade": false,
          "grade_id": "cell-setup",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# Install MLatom â€” our machine learning chemistry toolkit\n",
        "# This may take a minute. You'll see a lot of output â€” that's normal!\n",
        "!pip install mlatom -q\n",
        "print(\" MLatom installed!\")\n",
        "\n",
        "# Install other tools we need\n",
        "!pip install numpy matplotlib -q\n",
        "print(\" numpy and matplotlib ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "f92dc5af38bdc49be51ba7bc6bca8170",
          "grade": false,
          "grade_id": "cell-imports",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Import our tools â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "import numpy as np                  # for numerical calculations\n",
        "import matplotlib.pyplot as plt     # for plotting graphs\n",
        "from pathlib import Path            # for working with file paths\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility (everyone gets the same results)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Make plots look nice\n",
        "plt.rcParams['figure.figsize'] = (10, 5)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "print(\" All libraries imported successfully!\")\n",
        "print(f\"   numpy version: {np.__version__}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "75e2416ba8661cfc66682c63a88bf0bf",
          "grade": false,
          "grade_id": "cell-download-data",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Download the Hâ‚‚ dataset â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# R_451.dat   â†’ 451 H-H distances (in Ã…ngstrÃ¶ms)\n",
        "# E_FCI_451.dat â†’ the matching energies from Full Configuration Interaction\n",
        "\n",
        "# !wget -q https://raw.githubusercontent.com/dralgroup/MLinQCbook22-NN/main/R_451.dat\n",
        "# !wget -q https://raw.githubusercontent.com/dralgroup/MLinQCbook22-NN/main/E_FCI_451.dat\n",
        "\n",
        "# Load the data into numpy arrays\n",
        "R_all = np.loadtxt('R_451.dat', dtype=np.float64)\n",
        "E_all = np.loadtxt('E_FCI_451.dat', dtype=np.float64)\n",
        "\n",
        "print(f\" Data loaded!\")\n",
        "print(f\"   Number of data points : {len(R_all)}\")\n",
        "print(f\"   H-H distance range    : {R_all.min():.2f} â€“ {R_all.max():.2f} Ã…\")\n",
        "print(f\"   Energy range          : {E_all.min():.4f} â€“ {E_all.max():.4f} Hartree\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "eba52462265daa39c218001682543603",
          "grade": false,
          "grade_id": "cell-visualise-data",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Visualise the potential energy surface â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# This is the curve our model will try to learn!\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(R_all, E_all, 'b-', linewidth=2, label='FCI reference data')\n",
        "plt.xlabel('Hâ€“H Distance R (Ã…)', fontsize=12)\n",
        "plt.ylabel('Energy (Hartree)', fontsize=12)\n",
        "plt.title('Hâ‚‚ Potential Energy Surface â€” This is what we want to learn!', fontsize=13)\n",
        "\n",
        "# Mark the energy minimum\n",
        "idx_min = E_all.argmin()\n",
        "plt.scatter(R_all[idx_min], E_all[idx_min], color='red', s=150, zorder=5,\n",
        "            label=f'Equilibrium: R = {R_all[idx_min]:.3f} Ã…')\n",
        "plt.annotate('Equilibrium\\n(most stable geometry)', \n",
        "             xy=(R_all[idx_min], E_all[idx_min]),\n",
        "             xytext=(R_all[idx_min]+0.5, E_all[idx_min]+0.1),\n",
        "             arrowprops=dict(arrowstyle='->', color='red'),\n",
        "             fontsize=10, color='red')\n",
        "\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n The true FCI equilibrium bond length is {R_all[idx_min]:.4f} Ã…\")\n",
        "print(   \"   Our ML model should find something very close to this.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 2: Training the KREG Model \n",
        "\n",
        "## How does KREG work? An analogy \n",
        "\n",
        "Imagine you want to estimate the house price in a new neighbourhood.  \n",
        "You look at nearby houses that *you already know the prices of*, and weight their prices by how *similar* (close) they are to your target neighbourhood.\n",
        "\n",
        "KREG does the same thing with molecular geometries:\n",
        "- **\"Houses\"** = training geometries (H-H distances you already have energies for)\n",
        "- **\"Price\"** = energy\n",
        "- **\"Similarity\"** = the Gaussian kernel function\n",
        "\n",
        "$$E_{pred}(R) = \\sum_i \\alpha_i \\cdot K(R, R_i)$$\n",
        "\n",
        "where $K(R, R_i) = \\exp\\!\\left(-\\dfrac{(R-R_i)^2}{2\\sigma^2}\\right)$ is the **Gaussian kernel** (bell-shaped similarity).\n",
        "\n",
        "The $\\alpha_i$ are learned weights â€” training finds the best values!\n",
        "\n",
        "> **Nothing to fill in here â€” just run each cell!**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fead5d6adb8777db517e32b835afa35c",
          "grade": false,
          "grade_id": "cell-kreg-functions",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Core KREG functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "#\n",
        "# These are provided for you. You will USE these functions in the exercises.\n",
        "# Read the docstrings to understand what each one does.\n",
        "\n",
        "def gaussian_kernel(R1, R2, sigma):\n",
        "    \"\"\"\n",
        "    Gaussian kernel: measures how SIMILAR two geometries are.\n",
        "    - Returns 1.0 when R1 == R2 (identical â†’ perfectly similar)\n",
        "    - Returns ~0.0 when they are far apart (very different)\n",
        "    - sigma controls how quickly similarity drops off with distance\n",
        "    \"\"\"\n",
        "    return np.exp(-((R1 - R2) ** 2) / (2 * sigma ** 2))\n",
        "\n",
        "\n",
        "def build_kernel_matrix(R_train, sigma):\n",
        "    \"\"\"\n",
        "    Build the NÃ—N kernel matrix K where K[i,j] = kernel(R_train[i], R_train[j]).\n",
        "    This captures how similar every training point is to every other.\n",
        "    \"\"\"\n",
        "    n = len(R_train)\n",
        "    K = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            K[i, j] = gaussian_kernel(R_train[i], R_train[j], sigma)\n",
        "    return K\n",
        "\n",
        "\n",
        "def train_kreg(R_train, E_train, sigma, lam):\n",
        "    \"\"\"\n",
        "    Train the KREG model.\n",
        "    Solves (K + Î»I)Î± = E for the weight vector Î±.\n",
        "    Î» is regularisation â€” it prevents overfitting to noise.\n",
        "    \"\"\"\n",
        "    K = build_kernel_matrix(R_train, sigma)\n",
        "    K_reg = K + lam * np.eye(len(R_train))  # add regularisation\n",
        "    alpha = np.linalg.solve(K_reg, E_train)  # solve the linear system\n",
        "    return alpha\n",
        "\n",
        "\n",
        "def predict_kreg(R_new, R_train, alpha, sigma):\n",
        "    \"\"\"\n",
        "    Make predictions with the trained model.\n",
        "    For each new geometry, compute its similarity to ALL training points\n",
        "    and return the weighted sum of training energies.\n",
        "    \"\"\"\n",
        "    R_new = np.atleast_1d(R_new)\n",
        "    E_pred = np.zeros(len(R_new))\n",
        "    for i, r in enumerate(R_new):\n",
        "        k_vec = np.array([gaussian_kernel(r, r_train, sigma) for r_train in R_train])\n",
        "        E_pred[i] = np.dot(alpha, k_vec)\n",
        "    return E_pred if len(E_pred) > 1 else E_pred[0]\n",
        "\n",
        "\n",
        "print(\" KREG functions defined!\")\n",
        "print()\n",
        "print(\"   gaussian_kernel(R1, R2, sigma) â†’ similarity score between 0 and 1\")\n",
        "print(\"   train_kreg(R_train, E_train, sigma, lam) â†’ returns weights Î±\")\n",
        "print(\"   predict_kreg(R_new, R_train, alpha, sigma) â†’ energy prediction\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "93eb71e1a834ba6ec6efc9323f14934a",
          "grade": false,
          "grade_id": "cell-train-model",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Train the KREG model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "# Use all 451 points for training\n",
        "R_train = R_all.copy()\n",
        "E_train = E_all.copy()\n",
        "\n",
        "# Hyperparameters (found by cross-validation â€” don't worry about these for now)\n",
        "sigma_opt = 0.3    # controls kernel width\n",
        "lam_opt   = 1e-10  # regularisation strength\n",
        "\n",
        "print(\"Training KREG model... (this may take ~30 seconds)\")\n",
        "alpha = train_kreg(R_train, E_train, sigma=sigma_opt, lam=lam_opt)\n",
        "print(\" Model trained!\")\n",
        "print(f\"   sigma = {sigma_opt},  lambda = {lam_opt}\")\n",
        "print(f\"   Î± vector shape: {alpha.shape}  (one weight per training point)\")\n",
        "\n",
        "# Evaluate on a dense grid for plotting\n",
        "R_fine    = np.linspace(R_train.min(), R_train.max(), 500)\n",
        "E_pred_fine = predict_kreg(R_fine, R_train, alpha, sigma=sigma_opt)\n",
        "\n",
        "# Quick training accuracy check\n",
        "E_pred_train = predict_kreg(R_train, R_train, alpha, sigma=sigma_opt)\n",
        "mae = np.mean(np.abs(E_pred_train - E_train)) * 627.5  # Hartree â†’ kcal/mol\n",
        "print(f\"\\n   Training MAE: {mae:.4f} kcal/mol\")\n",
        "print(\"   (Chemical accuracy = 1 kcal/mol. Did we achieve it? ğŸ¯)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b841cbda609b6fd48cc6150664ef6563",
          "grade": false,
          "grade_id": "cell-plot-pes",
          "locked": true,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Visualise the trained model â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(R_train, E_train, 'o', markersize=3, alpha=0.4,\n",
        "         color='steelblue', label='FCI reference data (training)')\n",
        "plt.plot(R_fine, E_pred_fine, 'r-', linewidth=2.5,\n",
        "         label='KREG model prediction')\n",
        "\n",
        "plt.xlabel('Hâ€“H Distance R (Ã…)', fontsize=12)\n",
        "plt.ylabel('Energy (Hartree)', fontsize=12)\n",
        "plt.title('KREG Model vs. FCI Reference Data', fontsize=13)\n",
        "plt.legend(fontsize=11)\n",
        "plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Part 2 complete! Your KREG model is ready.\")\n",
        "print(\"   Now let's USE it for geometry optimisation in Part 3.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 3: Geometry Optimisation \n",
        "\n",
        "**Goal:** Find the H-H distance where the energy is *lowest* â€” the equilibrium geometry.\n",
        "\n",
        "## The Big Picture: Rolling a Ball Downhill \n",
        "\n",
        "Imagine placing a ball somewhere on the energy curve. If you nudge it in the direction of decreasing energy, it will roll down to the bottom.\n",
        "\n",
        "That's exactly what geometry optimisation does â€” mathematically!\n",
        "\n",
        "```\n",
        "  Energy\n",
        "   â”‚    \\          \n",
        "   â”‚     \\      /   â† high energy\n",
        "   â”‚      \\    /    \n",
        "   â”‚       \\__/     â† minimum energy (equilibrium)\n",
        "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ R (H-H distance)\n",
        "        â†‘\n",
        "     start here â†’ roll to minimum\n",
        "```\n",
        "\n",
        "The \"force\" on the atoms is the negative slope (gradient) of the energy:\n",
        "$$F(R) = -\\frac{dE}{dR}$$\n",
        "\n",
        "- If you're to the **right** of the minimum, the slope is positive â†’ force pushes **left** (towards minimum)\n",
        "- If you're to the **left** of the minimum, the slope is negative â†’ force pushes **right** (towards minimum)\n",
        "\n",
        "Each step: $R_{new} = R_{old} + \\text{step\\_size} \\times F(R_{old})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Exercise 3.1: Create Input Files for Optimisation (8 points)\n",
        "\n",
        "Before running an optimisation, we need two files:\n",
        "\n",
        "1. **`eq.xyz`** â€” an XYZ file describing the initial Hâ‚‚ geometry  \n",
        "   XYZ format is a standard chemistry file format:  \n",
        "   ```\n",
        "   2                            â† number of atoms\n",
        "   Comment line (any text)      â† description\n",
        "   H  0.000000  0.000000  0.000000   â† atom symbol + x, y, z coordinates\n",
        "   H  2.000000  0.000000  0.000000   â† second hydrogen at distance R_guess\n",
        "   ```\n",
        "\n",
        "2. **`opt.inp`** â€” an MLatom input file telling it what to do  \n",
        "   It needs three instructions:\n",
        "   - `geomopt` â€” run a geometry optimisation\n",
        "   - `MLmodelIn=energies.unf` â€” use our saved ML model\n",
        "   - `XYZfile=eq.xyz` â€” start from this geometry\n",
        "\n",
        "---\n",
        "\n",
        "**Your task:** Complete the two functions below.\n",
        "\n",
        "<details>\n",
        "<summary>ğŸ’¡ Hint for <code>create_initial_geometry</code> (click to expand)</summary>\n",
        "\n",
        "You need to write 4 lines to the file:  \n",
        "1. Number of atoms: `\"2\\n\"`  \n",
        "2. A comment: `\"Initial guess for H2 optimization\\n\"`  \n",
        "3. First H atom at origin: `\"H  0.000000  0.000000  0.000000\\n\"`  \n",
        "4. Second H atom at distance `R_guess` along x-axis: use an f-string like `f\"H  {R_guess:.6f}  0.000000  0.000000\\n\"`\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>ğŸ’¡ Hint for <code>create_opt_input</code> (click to expand)</summary>\n",
        "\n",
        "Write 4 lines:  \n",
        "```\n",
        "geomopt\n",
        "optProg=Gaussian\n",
        "MLmodelIn=energies.unf\n",
        "XYZfile=eq.xyz\n",
        "```\n",
        "\n",
        "Use `f.write(\"geomopt\\n\")` for the first line, and so on.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3eeb3d5b0d710190af9210787febfaec",
          "grade": false,
          "grade_id": "create_opt_files",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def create_initial_geometry(R_guess=2.0, filename='eq.xyz'):\n",
        "    \"\"\"\n",
        "    Write an XYZ file describing an Hâ‚‚ molecule.\n",
        "    \n",
        "    The first H atom sits at the origin (0,0,0).\n",
        "    The second H atom sits along the x-axis at position (R_guess, 0, 0).\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    R_guess : float\n",
        "        Initial H-H distance in Ã…ngstrÃ¶ms (our starting guess)\n",
        "    filename : str\n",
        "        Name of the file to create\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def create_opt_input(model_file='energies.unf',\n",
        "                     xyz_file='eq.xyz',\n",
        "                     filename='opt.inp'):\n",
        "    \"\"\"\n",
        "    Write an MLatom input file for geometry optimisation.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model_file : str\n",
        "        Path to the saved ML model\n",
        "    xyz_file : str\n",
        "        Path to the initial geometry XYZ file\n",
        "    filename : str\n",
        "        Name of the input file to create\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "# â”€â”€ Run your functions â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "initial_guesses = [1.0, 1.5, 2.0, 2.5]\n",
        "\n",
        "print(\"Creating optimisation files...\\n\")\n",
        "\n",
        "for i, R_init in enumerate(initial_guesses):\n",
        "    xyz_name = f'eq_{i}.xyz'\n",
        "    create_initial_geometry(R_init, xyz_name)\n",
        "    print(f\"  âœ“ Created {xyz_name}  (initial guess: R = {R_init:.1f} Ã…)\")\n",
        "\n",
        "# Create the main files\n",
        "create_initial_geometry(2.0, 'eq.xyz')\n",
        "create_opt_input()\n",
        "\n",
        "print(\"\\n  âœ“ Created eq.xyz  (main initial geometry)\")\n",
        "print(\"  âœ“ Created opt.inp\")\n",
        "\n",
        "# Show the file contents so you can check your work\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"Contents of opt.inp:\")\n",
        "print(\"=\"*50)\n",
        "with open('opt.inp', 'r') as f:\n",
        "    print(f.read())\n",
        "\n",
        "print(\"Contents of eq.xyz:\")\n",
        "print(\"=\"*50)\n",
        "with open('eq.xyz', 'r') as f:\n",
        "    print(f.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "a96a5f5cb0e279051abd10c5dfb5df95",
          "grade": true,
          "grade_id": "test_opt_files",
          "locked": true,
          "points": 8,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Automated tests (do not modify) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "assert Path('eq.xyz').exists(), \"âŒ eq.xyz was not created â€” did you call create_initial_geometry(2.0, 'eq.xyz')?\"\n",
        "assert Path('opt.inp').exists(), \"âŒ opt.inp was not created â€” did you call create_opt_input()?\"\n",
        "\n",
        "with open('opt.inp', 'r') as f:\n",
        "    content = f.read()\n",
        "assert 'geomopt' in content, \"âŒ opt.inp should contain 'geomopt'\"\n",
        "assert 'MLmodelIn' in content, \"âŒ opt.inp should contain 'MLmodelIn'\"\n",
        "\n",
        "with open('eq.xyz', 'r') as f:\n",
        "    lines = f.readlines()\n",
        "assert lines[0].strip() == '2', \"âŒ First line of eq.xyz should be '2' (number of atoms)\"\n",
        "assert 'H' in lines[2], \"âŒ Third line should define the first H atom\"\n",
        "assert 'H' in lines[3], \"âŒ Fourth line should define the second H atom\"\n",
        "\n",
        "print(\"âœ… All tests passed! (8/8 points)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Exercise 3.2: Implement the Gradient Descent Optimiser (12 points)\n",
        "\n",
        "Now you'll write the heart of geometry optimisation: **gradient descent**.\n",
        "\n",
        "## Step-by-Step Algorithm\n",
        "\n",
        "```\n",
        "1. Start at some initial distance Râ‚€\n",
        "2. Repeat:\n",
        "   a. Compute the force F = -dE/dR  (slope of energy curve)\n",
        "   b. If |F| is tiny â†’ we're at the minimum, STOP\n",
        "   c. Otherwise, move:  R_new = R_old + step_size Ã— F\n",
        "3. Return the final R (our optimised geometry)\n",
        "```\n",
        "\n",
        "## The Force Formula\n",
        "\n",
        "For the Gaussian kernel $K(R, R_i) = \\exp(-a(R-R_i)^2)$, the derivative is:\n",
        "\n",
        "$$\\frac{dK}{dR} = -\\frac{(R - R_i)}{\\sigma^2} \\cdot K(R, R_i)$$\n",
        "\n",
        "So the force is:\n",
        "\n",
        "$$F(R) = -\\frac{dE}{dR} = -\\sum_i \\alpha_i \\frac{dK}{dR}$$\n",
        "\n",
        "---\n",
        "\n",
        "**Your task:** Complete the two functions below.\n",
        "\n",
        "<details>\n",
        "<summary>ğŸ’¡ Hint for <code>compute_force_kreg</code> (click to expand)</summary>\n",
        "\n",
        "Loop over training points. For each training point `R_train[i]` with weight `alpha[i]`:  \n",
        "1. Compute `K_val = gaussian_kernel(R, R_train[i], sigma)` â€” the kernel value  \n",
        "2. Compute `dK_dR = -(R - R_train[i]) / (sigma**2) * K_val` â€” the kernel gradient  \n",
        "3. Add `-alpha[i] * dK_dR` to the force  \n",
        "\n",
        "The `-` sign converts energy gradient to force.\n",
        "\n",
        "</details>\n",
        "\n",
        "<details>\n",
        "<summary>ğŸ’¡ Hint for <code>optimize_geometry</code> (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "R_current = R_init\n",
        "for iteration in range(max_iter):\n",
        "    force = compute_force_kreg(R_current, R_train, alpha, sigma)\n",
        "    if abs(force) < tol:\n",
        "        break  # converged!\n",
        "    R_new = R_current + step_size * force\n",
        "    R_current = R_new\n",
        "return R_current, trajectory\n",
        "```\n",
        "\n",
        "Don't forget to clip `R_new` to reasonable bounds (e.g., between 0.5 and 5.0 Ã…)  \n",
        "and record each step in `trajectory`.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "883e4c19f53a4ef6161870349b46a091",
          "grade": false,
          "grade_id": "implement_optimization",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "def compute_force_kreg(R, R_train, alpha, sigma=0.3):\n",
        "    \"\"\"\n",
        "    Compute the force on the Hâ‚‚ molecule at distance R.\n",
        "    \n",
        "    Force = negative gradient of energy = -dE/dR\n",
        "    \n",
        "    For our KREG model:\n",
        "        F(R) = -Î£áµ¢ Î±áµ¢ Â· dK/dR\n",
        "    where:\n",
        "        dK/dR = -(R - Ráµ¢)/ÏƒÂ² Â· K(R, Ráµ¢)\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    R       : float â€” current H-H distance (Ã…)\n",
        "    R_train : array â€” training distances\n",
        "    alpha   : array â€” trained model weights\n",
        "    sigma   : float â€” kernel width parameter\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    force : float â€” force at position R\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def optimize_geometry(R_init, R_train, alpha, sigma=0.3,\n",
        "                      max_iter=100, tol=1e-6, step_size=0.01):\n",
        "    \"\"\"\n",
        "    Optimise the Hâ‚‚ geometry using gradient descent.\n",
        "    \n",
        "    Algorithm:\n",
        "    1. Start at R_init\n",
        "    2. Compute force at current position\n",
        "    3. Move in direction of force: R_new = R + step_size * force\n",
        "    4. Repeat until |force| < tol (converged)\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    R_init    : float â€” starting H-H distance (Ã…)\n",
        "    R_train   : array â€” training distances\n",
        "    alpha     : array â€” trained model weights\n",
        "    sigma     : float â€” kernel width\n",
        "    max_iter  : int   â€” maximum number of steps\n",
        "    tol       : float â€” convergence threshold (stop when |force| < tol)\n",
        "    step_size : float â€” how big each step is\n",
        "    \n",
        "    Returns\n",
        "    -------\n",
        "    R_opt      : float â€” optimised bond length\n",
        "    trajectory : list  â€” list of (iteration, R, E) tuples recording the path\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "# â”€â”€ Run optimisation from multiple starting points â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"Optimising Hâ‚‚ geometry with KREG model...\\n\")\n",
        "\n",
        "results = []\n",
        "for R_init in [1.0, 1.5, 2.0, 2.5]:\n",
        "    print(f\"  Starting from R = {R_init:.2f} Ã…\")\n",
        "    R_opt, traj = optimize_geometry(R_init, R_train, alpha,\n",
        "                                    sigma=sigma_opt,\n",
        "                                    step_size=0.005, max_iter=200)\n",
        "    E_opt = predict_kreg(R_opt, R_train, alpha, sigma=sigma_opt)\n",
        "    results.append((R_init, R_opt, E_opt, traj))\n",
        "    print(f\"      â†’ Optimised R = {R_opt:.4f} Ã…,  E = {E_opt:.6f} Ha\\n\")\n",
        "\n",
        "# â”€â”€ Visualise trajectories â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Left plot: trajectories on the PES\n",
        "ax1 = axes[0]\n",
        "ax1.plot(R_fine, E_pred_fine, 'k-', linewidth=2, alpha=0.3, label='KREG PES')\n",
        "colors = ['red', 'blue', 'green', 'purple']\n",
        "for (R_init, R_opt, E_opt, traj), color in zip(results, colors):\n",
        "    traj_arr = np.array(traj)\n",
        "    ax1.plot(traj_arr[:, 1], traj_arr[:, 2], 'o-', color=color,\n",
        "             linewidth=2, markersize=5, alpha=0.7, label=f'Start: {R_init:.1f} Ã…')\n",
        "    ax1.plot(R_opt, E_opt, '*', color=color, markersize=18,\n",
        "             markeredgecolor='black', markeredgewidth=1.5, zorder=5)\n",
        "ax1.set_xlabel('Hâ€“H Distance (Ã…)', fontsize=12)\n",
        "ax1.set_ylabel('Energy (Hartree)', fontsize=12)\n",
        "ax1.set_title('Optimisation Trajectories on PES\\n(â˜… = final minimum)', fontsize=12)\n",
        "ax1.legend(fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Right plot: energy vs. iteration\n",
        "ax2 = axes[1]\n",
        "for (R_init, R_opt, E_opt, traj), color in zip(results, colors):\n",
        "    traj_arr = np.array(traj)\n",
        "    ax2.plot(traj_arr[:, 0], traj_arr[:, 2], 'o-', color=color,\n",
        "             linewidth=2, markersize=4, label=f'Râ‚€ = {R_init:.1f} Ã…')\n",
        "ax2.set_xlabel('Step Number', fontsize=12)\n",
        "ax2.set_ylabel('Energy (Hartree)', fontsize=12)\n",
        "ax2.set_title('Energy Decreasing Over Optimisation Steps\\n(\"rolling downhill\")', fontsize=12)\n",
        "ax2.legend(fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# â”€â”€ Summary table â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "print(\"\\n\" + \"=\"*65)\n",
        "print(f\"{'Initial R (Ã…)':<16} {'Optimised R (Ã…)':<18} {'Final E (Ha)':<18} {'Steps'}\")\n",
        "print(\"-\"*65)\n",
        "for R_init, R_opt, E_opt, traj in results:\n",
        "    print(f\"{R_init:<16.2f} {R_opt:<18.4f} {E_opt:<18.6f} {len(traj)}\")\n",
        "print(\"=\"*65)\n",
        "\n",
        "# Compare with FCI reference\n",
        "R_fci_eq = R_train[E_train.argmin()]\n",
        "E_fci_min = E_train.min()\n",
        "R_kreg_eq = results[0][1]\n",
        "E_kreg_min = results[0][2]\n",
        "\n",
        "print(f\"\\n Comparison with FCI reference:\")\n",
        "print(f\"   FCI equilibrium : R = {R_fci_eq:.4f} Ã…,  E = {E_fci_min:.6f} Ha\")\n",
        "print(f\"   KREG optimised  : R = {R_kreg_eq:.4f} Ã…,  E = {E_kreg_min:.6f} Ha\")\n",
        "print(f\"   Difference      : Î”R = {abs(R_kreg_eq-R_fci_eq):.4f} Ã…,\"\n",
        "      f\" Î”E = {abs(E_kreg_min-E_fci_min)*627.5:.3f} kcal/mol\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "40cbd5249622ae97eb7d5eb27a7ac429",
          "grade": true,
          "grade_id": "test_optimization",
          "locked": true,
          "points": 12,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Automated tests (do not modify) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "R_test_opt, traj_test = optimize_geometry(2.0, R_train[:100],\n",
        "                                          alpha[:100], sigma=0.5,\n",
        "                                          max_iter=50)\n",
        "\n",
        "assert 1.0 < R_test_opt < 2.0, \\\n",
        "    f\"âŒ Optimised distance {R_test_opt:.4f} is outside expected range [1.0, 2.0] Ã…\"\n",
        "assert len(traj_test) > 1, \\\n",
        "    \"âŒ trajectory should have more than one step\"\n",
        "assert traj_test[-1][2] < traj_test[0][2], \\\n",
        "    \"âŒ energy should decrease over the optimisation (are you moving in the right direction?)\"\n",
        "\n",
        "# Check force function directly\n",
        "F_test = compute_force_kreg(2.0, R_train[:10], alpha[:10], sigma=0.3)\n",
        "assert isinstance(F_test, (float, np.floating)), \\\n",
        "    \"âŒ compute_force_kreg should return a single float value\"\n",
        "\n",
        "print(\"âœ… All tests passed! (12/12 points)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Try It Yourself! â€” Explore the Effect of Step Size\n",
        "\n",
        "> This cell won't be graded â€” it's for your own exploration!\n",
        "\n",
        "Try changing `step_size` below. What happens if it's:\n",
        "- Very small (e.g., `0.0001`)? â†’ Does it converge? How many steps?\n",
        "- Very large (e.g., `0.1`)? â†’ Does it still find the minimum?\n",
        "- Negative? â†’ What direction does it go?\n",
        "\n",
        "This is called a **hyperparameter** â€” a setting that controls the algorithm itself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# â”€â”€ Exploration cell â€” change the parameters and rerun! â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "\n",
        "step_size_to_try = 0.005    # â† try changing this!\n",
        "R_start = 2.0               # â† and this!\n",
        "\n",
        "R_opt_exp, traj_exp = optimize_geometry(\n",
        "    R_start, R_train, alpha,\n",
        "    sigma=sigma_opt,\n",
        "    step_size=step_size_to_try,\n",
        "    max_iter=300\n",
        ")\n",
        "traj_arr = np.array(traj_exp)\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax = axes[0]\n",
        "ax.plot(R_fine, E_pred_fine, 'k-', alpha=0.3, label='PES')\n",
        "ax.plot(traj_arr[:, 1], traj_arr[:, 2], 'ro-', markersize=5, label='Path')\n",
        "ax.plot(R_opt_exp, predict_kreg(R_opt_exp, R_train, alpha, sigma_opt),\n",
        "        '*', color='gold', markersize=20, markeredgecolor='black', zorder=5, label='Final')\n",
        "ax.set_xlabel('Hâ€“H Distance (Ã…)'); ax.set_ylabel('Energy (Ha)')\n",
        "ax.set_title(f'step_size = {step_size_to_try},  start = {R_start} Ã…')\n",
        "ax.legend(); ax.grid(alpha=0.3)\n",
        "\n",
        "ax2 = axes[1]\n",
        "ax2.plot(traj_arr[:, 0], traj_arr[:, 2], 'b-o', markersize=4)\n",
        "ax2.set_xlabel('Step'); ax2.set_ylabel('Energy (Ha)')\n",
        "ax2.set_title(f'Energy over {len(traj_exp)} steps')\n",
        "ax2.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "print(f\"Final optimised distance: {R_opt_exp:.4f} Ã…  ({len(traj_exp)} steps)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part 4: How Good Is Our Model? \n",
        "\n",
        "Training a model is not enough â€” we need to **validate** it. This means carefully measuring how accurate our predictions are.\n",
        "\n",
        "## Error Metrics Explained\n",
        "\n",
        "| Metric | Formula | Plain English |\n",
        "|--------|---------|---------------|\n",
        "| **MAE** | mean of \\|error\\| | Average mistake size |\n",
        "| **RMSE** | âˆš(mean of errorÂ²) | Penalises big mistakes more |\n",
        "| **RÂ²** | 1 âˆ’ SS_res/SS_tot | 1.0 = perfect, 0.0 = no better than average |\n",
        "\n",
        "**Chemical accuracy** = 1 kcal/mol â‰ˆ 0.00159 Hartree.  \n",
        "This is the threshold below which quantum chemistry predictions are considered accurate enough for most chemistry applications.\n",
        "\n",
        "## Useful Conversion\n",
        "\n",
        "1 Hartree = 627.5 kcal/mol"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "###  Exercise 4.1: Comprehensive Error Analysis (15 points)\n",
        "\n",
        "**Your task:** Complete the code below to:\n",
        "1. Compute MAE, RMSE, and Max Error (in Hartree and kcal/mol)\n",
        "2. Calculate what fraction of predictions are within chemical accuracy (< 1 kcal/mol)\n",
        "3. Compute RÂ²\n",
        "4. Create visualisation plots (code is provided â€” just make sure your variables are named correctly!)\n",
        "\n",
        "<details>\n",
        "<summary>ğŸ’¡ Hint: Computing error metrics (click to expand)</summary>\n",
        "\n",
        "```python\n",
        "# Predictions on training set\n",
        "E_pred_all = predict_kreg(R_train, R_train, alpha, sigma=sigma_opt)\n",
        "\n",
        "# Errors (difference between prediction and truth)\n",
        "errors = E_pred_all - E_train              # in Hartree\n",
        "errors_kcal = errors * 627.5              # convert to kcal/mol\n",
        "\n",
        "# MAE = mean absolute error\n",
        "mae_ha = np.mean(np.abs(errors))\n",
        "\n",
        "# RMSE = root mean squared error\n",
        "rmse_ha = np.sqrt(np.mean(errors**2))\n",
        "\n",
        "# Maximum error\n",
        "max_error_ha = np.max(np.abs(errors))\n",
        "\n",
        "# RÂ² score\n",
        "SS_res = np.sum(errors**2)\n",
        "SS_tot = np.sum((E_train - E_train.mean())**2)\n",
        "R2 = 1 - SS_res/SS_tot\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "8c6ed870c4e214a548b1406011bb5c84",
          "grade": false,
          "grade_id": "error_analysis",
          "locked": false,
          "points": 15,
          "schema_version": 3,
          "solution": true,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "19dca48efe38e4232652e21cc63ec4e4",
          "grade": true,
          "grade_id": "test_error_analysis",
          "locked": true,
          "points": 15,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Automated tests (do not modify) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "assert 'mae_ha' in dir() or 'mae_ha' in vars(), \\\n",
        "    \"âŒ mae_ha not defined â€” did you compute the Mean Absolute Error?\"\n",
        "assert 'rmse_ha' in dir() or 'rmse_ha' in vars(), \\\n",
        "    \"âŒ rmse_ha not defined â€” did you compute RMSE?\"\n",
        "assert 'R2' in dir() or 'R2' in vars(), \\\n",
        "    \"âŒ R2 not defined â€” did you compute the RÂ² score?\"\n",
        "\n",
        "assert mae_ha >= 0, \"âŒ MAE should be non-negative\"\n",
        "assert rmse_ha >= rmse_ha * 0, \"âŒ RMSE should be non-negative\"\n",
        "assert 0 <= R2 <= 1.0, f\"âŒ RÂ² should be between 0 and 1, got {R2:.4f}\"\n",
        "assert mae_kcal < 1.0, \\\n",
        "    f\"âŒ MAE = {mae_kcal:.4f} kcal/mol â€” this model should achieve chemical accuracy!\"\n",
        "\n",
        "print(\"âœ… All tests passed! (15/15 points)\")\n",
        "print(f\"   MAE = {mae_kcal:.4f} kcal/mol,  RÂ² = {R2:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# ğŸ’¬ Reflection Questions\n",
        "\n",
        "Take a few minutes to think about these â€” they'll help consolidate your understanding:\n",
        "\n",
        "1. **Why does starting from different initial geometries (R = 1.0, 1.5, 2.0, 2.5 Ã…) all lead to the same final answer?**  \n",
        "   *Hint: Think about the shape of the energy curve.*\n",
        "\n",
        "2. **What would happen if you used a very large step size in the optimiser?**  \n",
        "   *(You can test this in the exploration cell above!)*\n",
        "\n",
        "3. **The KREG model achieves very high accuracy â€” but we trained it on ALL the data. Can we trust this accuracy number?**  \n",
        "   *Hint: In ML, we usually need a separate test set. What does it mean when you evaluate on training data?*\n",
        "\n",
        "4. **We used Hâ‚‚ (just 2 atoms, 1 degree of freedom). What challenges would arise for larger molecules like water (Hâ‚‚O)?**\n",
        "\n",
        "5. **The summary says ML is \"1000Ã— faster than quantum chemistry\". When would you still prefer to use quantum chemistry instead?**\n",
        "\n",
        "---\n",
        "# Glossary\n",
        "\n",
        "| Term | Meaning |\n",
        "|------|---------|\n",
        "| **FCI** | Full Configuration Interaction â€” the most accurate (and expensive) quantum chemistry method |\n",
        "| **Hartree** | Unit of energy in quantum chemistry. 1 Hartree = 627.5 kcal/mol |\n",
        "| **Ã…ngstrÃ¶m (Ã…)** | Unit of length. 1 Ã… = 10â»Â¹â° m |\n",
        "| **Kernel** | A function that measures similarity between two data points |\n",
        "| **Regularisation (Î»)** | A penalty term that prevents the model from overfitting noise |\n",
        "| **Chemical accuracy** | Errors < 1 kcal/mol â€” the standard benchmark in computational chemistry |\n",
        "| **PES** | Potential Energy Surface â€” the energy as a function of molecular geometry |\n",
        "| **Gradient descent** | Algorithm for finding a minimum by repeatedly following the downhill slope |\n",
        "| **Î± (alpha) vector** | The learned weights in KREG, one per training point |\n",
        "| **RÂ² score** | Coefficient of determination â€” 1.0 means perfect prediction |\n",
        "\n",
        "---\n",
        "#  Summary\n",
        "\n",
        "## What You Accomplished\n",
        "\n",
        "âœ… **Loaded and visualised** the Hâ‚‚ potential energy surface from FCI quantum chemistry data  \n",
        "âœ… **Trained a KREG model** â€” a kernel machine learning potential â€” on the data  \n",
        "âœ… **Implemented gradient descent** to optimise the Hâ‚‚ bond length  \n",
        "âœ… **Validated the model** with MAE, RMSE, RÂ², and parity plots  \n",
        "âœ… **Achieved chemical accuracy** (< 1 kcal/mol)! \n",
        "\n",
        "## Key Insights\n",
        "\n",
        "- **Kernel methods** are powerful interpolators: they predict by measuring similarity to training examples\n",
        "- **ML potentials** give quantum-chemistry-level accuracy at a fraction of the computational cost\n",
        "- **Gradient descent** is a universal tool for finding minima â€” it appears in training neural networks too!\n",
        "- **Error analysis** is essential: always check *where* and *how much* your model is wrong\n",
        "\n",
        "## What Comes Next?\n",
        "\n",
        "- More complex molecules (Hâ‚‚O, CHâ‚„, organic molecules with many degrees of freedom)\n",
        "- **Molecular dynamics**: use the ML potential to simulate atomic motion over time\n",
        "- **Neural network potentials**: replace the kernel with a deep neural network\n",
        "- **Advanced descriptors**: SOAP, Behler-Parrinello symmetry functions\n",
        "\n",
        "---\n",
        "\n",
        "## References\n",
        "\n",
        "1. Yi-Fan Hou and Pavlo O. Dral. *Kernel method potentials.* In Quantum Chemistry in the Age of Machine Learning, Elsevier (2023). DOI: 10.1016/B978-0-323-90049-2.00020-2\n",
        "2. MLatom Package: http://MLatom.com\n",
        "3. MLatom@XACS Cloud: http://XACScloud.com\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "torch",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}