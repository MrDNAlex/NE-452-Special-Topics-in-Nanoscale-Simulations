{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Lab: Gaussian Process Regression for Molecular Energy Prediction\n",
    "\n",
    "**Learning Objectives:**\n",
    "- Understand Gaussian Process Regression (GPR) fundamentals\n",
    "- Implement different kernel functions from scratch\n",
    "- Compare kernel performance on real molecular data\n",
    "- Learn hyperparameter optimization through Bayesian inference\n",
    "\n",
    "**Pedagogical Flow:**\n",
    "1.  **Explore** - Understand the data and problem\n",
    "2.  **Build** - Implement simple kernel functions\n",
    "3.  **Enhance** - Add complexity with full GPR class\n",
    "4.  **Compare** - Test different kernels\n",
    "5.  **Reflect** - Analyze and discuss results\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Installing Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scipy numpy matplotlib -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 1:  EXPLORE - Understanding the Data\n",
    "\n",
    "We're working with molecular energy data where:\n",
    "- **X (R)**: Atomic distances in Angstroms\n",
    "- **Y (E_FCI)**: Full Configuration Interaction energies in Hartree units\n",
    "\n",
    "Our goal: **Predict energy at any distance using only 16 training points**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download H2 molecule data\n",
    "!wget -q https://raw.githubusercontent.com/dralgroup/MLinQCbook22-NN/main/R_451.dat\n",
    "!wget -q https://raw.githubusercontent.com/dralgroup/MLinQCbook22-NN/main/E_FCI_451.dat\n",
    "print(\"Dataset downloaded!\")\n",
    "print(\"- R_451.dat: Internuclear distances (451 points)\")\n",
    "print(\"- E_FCI_451.dat: FCI energies (451 points)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load full dataset\n",
    "x_raw = np.loadtxt('R_451.dat')\n",
    "y_raw = np.loadtxt('E_FCI_451.dat')\n",
    "\n",
    "# Sample 16 training points\n",
    "idx = np.arange(0, 451, int(451/16))\n",
    "x, y = x_raw[idx], y_raw[idx]\n",
    "\n",
    "# Create prediction grid\n",
    "X = np.linspace(0.5, 5, 200)\n",
    "\n",
    "print(f\"Training data: {len(x)} points\")\n",
    "print(f\"Prediction grid: {len(X)} points\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1.1: Visualize the Training Data (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f710531cb930cadeb28efb36c561b856",
     "grade": false,
     "grade_id": "visualize_data",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Create a scatter plot of the training data\n",
    "# - Plot x vs y with red 'o' markers\n",
    "# - Add labels: \"Atomic Distance (Angstrom)\" and \"Energy (Hartree)\"\n",
    "# - Add a title: \"Molecular Energy Training Data\"\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2e4b0f1cefa7d06cfa7d3ee5c79a87b3",
     "grade": true,
     "grade_id": "test_visualize",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test: Check that plot was created\n",
    "assert len(plt.get_fignums()) > 0, \"No figure was created\"\n",
    "print(\"✓ Visualization created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 2: BUILD - Implementing Kernel Functions\n",
    "\n",
    "Kernels measure similarity between points. Let's implement the most common kernels!\n",
    "\n",
    "## Mathematical Background\n",
    "\n",
    "### Distance Matrix\n",
    "For any two matrices $X_1$ (size $n \\times d$) and $X_2$ (size $m \\times d$):\n",
    "\n",
    "$$\\text{dist}^2_{ij} = ||x_{1i} - x_{2j}||^2 = \\sum_{k=1}^{d}(x_{1ik} - x_{2jk})^2$$\n",
    "\n",
    "Efficiently computed as:\n",
    "$$D^2 = \\sum x_1^2 \\mathbf{1}^T + \\mathbf{1}(\\sum x_2^2)^T - 2X_1X_2^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.1: Implement RBF (Radial Basis Function) Kernel (5 points)\n",
    "\n",
    "The RBF kernel (also called Squared Exponential) is:\n",
    "\n",
    "$$K(x_1, x_2) = \\sigma^2 \\exp\\left(-\\frac{||x_1-x_2||^2}{2l^2}\\right)$$\n",
    "\n",
    "Where:\n",
    "- $\\sigma$ controls the vertical scale (amplitude)\n",
    "- $l$ controls the horizontal scale (length scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "678f7098845446858eea2cff9d125f07",
     "grade": false,
     "grade_id": "rbf_kernel",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def RBF_kernel(x1, x2, l=1.0, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute RBF kernel matrix.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    x1 : array (n, d) - First set of points\n",
    "    x2 : array (m, d) - Second set of points\n",
    "    l : float - Length scale parameter\n",
    "    sigma : float - Amplitude parameter\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    K : array (n, m) - Kernel matrix\n",
    "    \"\"\"\n",
    "    # TODO: Implement the RBF kernel\n",
    "    # Hint: Use the efficient distance calculation shown above\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29ce1217b2e23116a3a036b72811ae7c",
     "grade": true,
     "grade_id": "test_rbf",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test RBF kernel\n",
    "test_x1 = np.array([[0], [1], [2]])\n",
    "test_x2 = np.array([[0], [1]])\n",
    "K = RBF_kernel(test_x1, test_x2, l=1.0, sigma=1.0)\n",
    "\n",
    "assert K.shape == (3, 2), f\"Wrong shape: {K.shape}, expected (3, 2)\"\n",
    "assert np.isclose(K[0, 0], 1.0), \"Diagonal should be 1.0 when sigma=1\"\n",
    "assert K[0, 0] > K[0, 1], \"Kernel should decrease with distance\"\n",
    "assert np.all(K >= 0), \"Kernel values should be non-negative\"\n",
    "print(\"✓ RBF kernel implemented correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.2: Implement Matérn 3/2 Kernel (5 points)\n",
    "\n",
    "$$K(x_1, x_2) = \\sigma^2 \\left(1 + \\frac{\\sqrt{3}||x_1-x_2||}{l}\\right) \\exp\\left(-\\frac{\\sqrt{3}||x_1-x_2||}{l}\\right)$$\n",
    "\n",
    "This kernel produces rougher functions than RBF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a7405a1352a06c3eda69c01cbb0ac52a",
     "grade": false,
     "grade_id": "matern_kernel",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def Matern_kernel(x1, x2, l=1.0, sigma=1.0):\n",
    "    \"\"\"\n",
    "    Compute Matérn 3/2 kernel matrix.\n",
    "    \n",
    "    Parameters: Same as RBF_kernel\n",
    "    Returns: K : array (n, m) - Kernel matrix\n",
    "    \"\"\"\n",
    "    # TODO: Implement Matérn 3/2 kernel\n",
    "    # Step 1: Compute distance matrix (use sqrt this time!)\n",
    "    # Step 2: Apply the Matérn 3/2 formula\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4f6b84c1561f730413287c1648ae4a18",
     "grade": true,
     "grade_id": "test_matern",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test Matérn kernel\n",
    "K_matern = Matern_kernel(test_x1, test_x2, l=1.0, sigma=1.0)\n",
    "\n",
    "assert K_matern.shape == (3, 2), f\"Wrong shape: {K_matern.shape}\"\n",
    "assert np.isclose(K_matern[0, 0], 1.0, atol=1e-6), \"Diagonal should be ~1.0 when sigma=1\"\n",
    "assert K_matern[0, 0] > K_matern[0, 1], \"Kernel should decrease with distance\"\n",
    "print(\"✓ Matérn 3/2 kernel implemented correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2.3: Visualize Kernel Behavior (3 points)\n",
    "\n",
    "Let's see how these kernels behave differently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "de3521b97fac4a71ed8d4b126de4c8c0",
     "grade": false,
     "grade_id": "kernel_comparison",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Compare kernel behavior\n",
    "# 1. Create distances from 0 to 3 with 100 points\n",
    "# 2. Compute RBF and Matérn kernels for distance from origin\n",
    "# 3. Plot both on the same figure with legend\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "627a2c3d8ee0d84a7e0c0018b74bb03c",
     "grade": true,
     "grade_id": "test_kernel_viz",
     "locked": true,
     "points": 3,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test: Check that comparison plot was created\n",
    "assert len(plt.get_fignums()) > 0, \"No figure created\"\n",
    "print(\"✓ Kernel comparison visualized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 3:  ENHANCE - Building the Full GPR Class\n",
    "\n",
    "## Theory: Gaussian Process Regression\n",
    "\n",
    "### Joint Distribution\n",
    "$$\\begin{bmatrix} f(x) \\\\ \\boldsymbol{y}^* \\end{bmatrix} \\sim \\mathcal{N} \\left( \\begin{bmatrix} \\mu_f \\\\ \\mu_y \\end{bmatrix}, \\begin{bmatrix} K_{ff} & K_{fy} \\\\ K_{fy}^T & K_{yy} \\end{bmatrix} \\right)$$\n",
    "\n",
    "### Posterior Prediction\n",
    "$$f(x^*) \\sim \\mathcal{N}(\\mu^*, \\Sigma^*)$$\n",
    "\n",
    "Where:\n",
    "- **Mean**: $\\mu^* = K_{fy}^T (K_{ff} + \\sigma^2 I)^{-1} \\boldsymbol{y}$\n",
    "- **Covariance**: $\\Sigma^* = K_{yy} - K_{fy}^T (K_{ff} + \\sigma^2 I)^{-1} K_{fy}$\n",
    "\n",
    "### Hyperparameter Optimization (Negative Log Likelihood)\n",
    "$$\\mathcal{L} = \\frac{1}{2}\\boldsymbol{y}^T K^{-1}\\boldsymbol{y} + \\frac{1}{2}\\log|K| + \\frac{n}{2}\\log(2\\pi)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full GPR implementation (provided)\n",
    "class GPR():\n",
    "    def __init__(self, kernel='RBF', optimizer='L-BFGS-B', opt_params=None, bounds=None, **kw):\n",
    "        self.optimizer = optimizer\n",
    "        self.kernel = getattr(self, kernel)\n",
    "        self.params = {\n",
    "            \"l\": 0.5,\n",
    "            \"sigma\": 0.2,\n",
    "            \"alpha\": 1e-8\n",
    "        }\n",
    "        self.opt_params = opt_params\n",
    "        self.bounds = bounds\n",
    "        for k, v in kw.items():\n",
    "            self.params[k] = v\n",
    "        self.is_fit = False\n",
    "        self.train_X, self.train_y = None, None\n",
    "\n",
    "    def predict(self, X, return_std=False):\n",
    "        X = np.asarray(X)\n",
    "        if not self.is_fit:\n",
    "            mean = np.zeros(X.shape[0])\n",
    "            cov = self.kernel(X, X)\n",
    "            if return_std:\n",
    "                return mean, np.sqrt(np.diag(cov))\n",
    "            return mean, cov\n",
    "        \n",
    "        Kff = self.kernel(self.train_X, self.train_X)\n",
    "        Kyy = self.kernel(X, X)\n",
    "        Kfy = self.kernel(self.train_X, X)\n",
    "        Kff_inv = np.linalg.inv(Kff + self.params[\"alpha\"] * np.eye(len(self.train_X)))\n",
    "        \n",
    "        mu = Kfy.T.dot(Kff_inv).dot(self.train_y).ravel()\n",
    "        cov = Kyy - Kfy.T.dot(Kff_inv).dot(Kfy)\n",
    "        if return_std:\n",
    "            return mu, np.sqrt(np.diag(cov))\n",
    "        return mu, cov\n",
    "\n",
    "    def RBF(self, x1, x2):\n",
    "        dist_matrix = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)\n",
    "        return self.params[\"sigma\"]**2 * np.exp(-0.5 / self.params[\"l\"]**2 * dist_matrix)\n",
    "    \n",
    "    def Exponential(self, x1, x2):\n",
    "        dist_matrix = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)\n",
    "        dist_matrix = dist_matrix**0.5\n",
    "        return self.params['sigma']**2 * np.exp(-1/self.params['l'] * dist_matrix)\n",
    "    \n",
    "    def Matern(self, x1, x2):\n",
    "        dist_matrix = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)\n",
    "        dist_matrix = dist_matrix**0.5\n",
    "        tmp1 = 1 + 3**0.5 * dist_matrix / self.params['l']\n",
    "        tmp2 = np.exp(-3**0.5 * dist_matrix / self.params['l'])\n",
    "        return self.params['sigma']**2 * tmp1 * tmp2\n",
    "    \n",
    "    def RationalQuadratic(self, x1, x2):\n",
    "        dist_matrix = np.sum(x1**2, 1).reshape(-1, 1) + np.sum(x2**2, 1) - 2 * np.dot(x1, x2.T)\n",
    "        alpha = self.params['kernel_alpha']\n",
    "        l = self.params['l']\n",
    "        inner = 1 + dist_matrix / (2 * alpha * l**2)\n",
    "        return self.params['sigma']**2 * inner**(-alpha)\n",
    "    \n",
    "    def sample_y(self, X, n_samples=5, random_state=0):\n",
    "        mean, cov = self.predict(X[:, np.newaxis])\n",
    "        rs = np.random.RandomState(random_state)\n",
    "        return rs.multivariate_normal(mean, cov, n_samples).T\n",
    "    \n",
    "    def negative_log_likelihood_loss(self, params):\n",
    "        for k, v in zip(self.opt_params, params):\n",
    "            self.params[k] = v\n",
    "        Kyy = self.kernel(self.train_X, self.train_X) + self.params[\"alpha\"] * np.eye(len(self.train_X))\n",
    "        loss = 0.5 * self.train_y.T.dot(np.linalg.inv(Kyy)).dot(self.train_y) + \\\n",
    "               0.5 * np.linalg.slogdet(Kyy)[1] + \\\n",
    "               0.5 * len(self.train_X) * np.log(2 * np.pi)\n",
    "        return loss.ravel()\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.train_X = np.asarray(X)\n",
    "        self.train_y = np.asarray(y)\n",
    "        \n",
    "        if self.optimizer and self.opt_params:\n",
    "            res = minimize(self.negative_log_likelihood_loss,\n",
    "                         [self.params[k] for k in self.opt_params],\n",
    "                         bounds=self.bounds,\n",
    "                         method=self.optimizer)\n",
    "            for i, k in enumerate(self.opt_params):\n",
    "                self.params[k] = res.x[i]\n",
    "        self.is_fit = True\n",
    "\n",
    "print(\"✓ GPR class loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.1: Create Visualization Function (5 points)\n",
    "\n",
    "Complete the function to visualize prior and posterior distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0196031d154f5c8f3552e875a88c3c3a",
     "grade": false,
     "grade_id": "draw_function",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def draw(gpr, title):\n",
    "    \"\"\"\n",
    "    Visualize GPR prior and posterior.\n",
    "    \n",
    "    TODO: Complete the posterior subplot (subplot 122)\n",
    "    - Fit the model with training data\n",
    "    - Make predictions\n",
    "    - Plot training points, mean prediction, and confidence interval\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(20, 6), dpi=100)\n",
    "    \n",
    "    # PRIOR (provided)\n",
    "    plt.subplot(121)\n",
    "    ypred, std = gpr.predict(X[:, np.newaxis], return_std=True)\n",
    "    plt.plot(X, ypred, 'k', lw=2, label='Mean')\n",
    "    plt.fill_between(X, ypred+1.96*std, ypred-1.96*std, alpha=0.2, label='95% CI')\n",
    "    y_samples = gpr.sample_y(X, n_samples=10)\n",
    "    plt.plot(X, y_samples, alpha=0.3)\n",
    "    plt.title('Prior Distribution')\n",
    "    plt.xlabel('R (Angstrom)')\n",
    "    plt.ylabel('E (Hartree)')\n",
    "    plt.legend()\n",
    "    \n",
    "    # POSTERIOR (student implements)\n",
    "    plt.subplot(122)\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "    \n",
    "    plt.suptitle(title, fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{title.replace(\" \", \"_\")}.png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c8412eff0173ccfcc3c36d8f8dc33da",
     "grade": true,
     "grade_id": "test_draw",
     "locked": true,
     "points": 5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test the draw function\n",
    "test_gpr = GPR(l=1.0, sigma=0.1)\n",
    "draw(test_gpr, \"Test GPR Visualization\")\n",
    "assert test_gpr.is_fit == True, \"Model should be fitted\"\n",
    "print(\"✓ Visualization function works correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3.2: Calculate Initial Hyperparameters (2 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d684ee8aea3b3808b3a35f917f6b446f",
     "grade": false,
     "grade_id": "init_params",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate good initial guesses for l and sigma\n",
    "# Hint: Use standard deviation of x for l, and y.std() / sqrt(2) for sigma\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "\n",
    "print(f\"Initial length scale (l): {l:.4f}\")\n",
    "print(f\"Initial sigma: {sigma:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f64a94cf866a1e591c7f0b406584fe4f",
     "grade": true,
     "grade_id": "test_init_params",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test initial parameters\n",
    "assert 0.5 < l < 3.0, f\"Length scale seems wrong: {l}\"\n",
    "assert 0.01 < sigma < 0.1, f\"Sigma seems wrong: {sigma}\"\n",
    "print(\"✓ Initial parameters calculated correctly!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 4:  COMPARE - Testing Different Kernels\n",
    "\n",
    "Now let's compare how different kernels perform on our molecular data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1: RBF Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_rbf = GPR(opt_params='l sigma alpha'.split(),\n",
    "              bounds=((1e-4, 1e4), (1e-4, 1e4), (1e-10, 1e4)),\n",
    "              l=l, sigma=sigma, alpha=1e-6)\n",
    "draw(gpr_rbf, 'RBF Kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2: Matérn 3/2 Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_matern = GPR(kernel='Matern',\n",
    "                 opt_params='l sigma alpha'.split(),\n",
    "                 bounds=((1e-4, 1e4), (1e-4, 1e4), (1e-10, 1e4)),\n",
    "                 l=l, sigma=sigma, alpha=1e-6)\n",
    "draw(gpr_matern, 'Matérn 3/2 Kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3: Exponential Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_exp = GPR(kernel='Exponential',\n",
    "              opt_params='l sigma alpha'.split(),\n",
    "              bounds=((1e-4, 1e4), (1e-4, 1e4), (1e-10, 1e4)),\n",
    "              l=l, sigma=sigma, alpha=1e-6)\n",
    "draw(gpr_exp, 'Exponential Kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4: Rational Quadratic Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpr_rq = GPR(kernel='RationalQuadratic',\n",
    "             opt_params='l sigma alpha'.split(),\n",
    "             bounds=[(1e-4, 1e4), (1e-4, 1e4), (1e-10, 1e4)],\n",
    "             kernel_alpha=10,\n",
    "             l=l, sigma=sigma, alpha=1e-6)\n",
    "draw(gpr_rq, 'Rational Quadratic Kernel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4.1: Quantitative Comparison (8 points)\n",
    "\n",
    "Compare the kernels using Mean Squared Error (MSE) on held-out test points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "20c911fbef68520acac8cd862b8648ca",
     "grade": false,
     "grade_id": "kernel_comparison_mse",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Calculate MSE for each kernel on the full dataset\n",
    "# 1. Get predictions for all points in x_raw\n",
    "# 2. Calculate MSE = mean((y_pred - y_true)^2)\n",
    "# 3. Store results in a dictionary\n",
    "# 4. Print comparison table\n",
    "\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c93b89b744e47e56ba61303bb468d6ac",
     "grade": true,
     "grade_id": "test_comparison",
     "locked": true,
     "points": 8,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Test: Check that comparison was performed\n",
    "assert 'results' in locals(), \"Results dictionary not created\"\n",
    "assert len(results) == 4, \"Should have 4 kernel results\"\n",
    "assert all('mse' in v for v in results.values()), \"Missing MSE values\"\n",
    "print(\"✓ Kernel comparison completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Part 5:  REFLECT - Analysis and Discussion\n",
    "\n",
    "Answer the following questions based on your experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5.1: Conceptual Understanding (10 points)\n",
    "\n",
    "Answer each question in 2-3 sentences in the markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cac15e0fe25ca38afe9b638711fd8088",
     "grade": true,
     "grade_id": "reflection_questions",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#  Congratulations!\n",
    "\n",
    "You've successfully:\n",
    "- ✅ Implemented kernel functions from scratch\n",
    "- ✅ Built and trained Gaussian Process Regression models\n",
    "- ✅ Compared different kernels quantitatively\n",
    "- ✅ Understood Bayesian inference for regression\n",
    "\n",
    "## Next Steps\n",
    "- Try implementing other kernels (Periodic, Linear)\n",
    "- Experiment with different datasets\n",
    "- Explore multi-dimensional inputs\n",
    "- Study sparse GPR for large datasets\n",
    "\n",
    "## References\n",
    "- Rasmussen & Williams: \"Gaussian Processes for Machine Learning\" (2006)\n",
    "- Murphy: \"Probabilistic Machine Learning: Advanced Topics\" (2023)\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.6.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
